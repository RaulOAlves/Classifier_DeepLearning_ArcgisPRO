{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RaulOAlves/Classifier_DeepLearning_ArcgisPRO/blob/main/Classifier_DeepLearning_ArcgisPRO.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aBnDnaGqRs5M"
      },
      "outputs": [],
      "source": [
        "# Importando as bibliotecas\n",
        "\n",
        "import arcpy\n",
        "from arcpy import env\n",
        "import os\n",
        "from arcpy.ia import *\n",
        "from arcgis.learn import *\n",
        "env.overwriteOutput = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X-BfkqQsRs5N"
      },
      "outputs": [],
      "source": [
        "# Diretórios de trabalho\n",
        "\n",
        "# Diretório GDB\n",
        "workspace1 = r'E:\\Cursos\\GeoAI\\GeoAI_03\\GeoAI_03.gdb'\n",
        "\n",
        "# Diretório raiz\n",
        "workspace2 = r'E:\\Cursos\\GeoAI\\GeoAI_03'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "abAK8CoXRs5O"
      },
      "outputs": [],
      "source": [
        "# Diretório de Imagens\n",
        "\n",
        "imagem_dir = r'E:\\Cursos\\GeoAI\\GeoAI_02\\Imagens'\n",
        "\n",
        "# Bandas\n",
        "\n",
        "b0 = os.path.join(imagem_dir, 'CBERS_4A_WPM_20210727_211_115_L4_BAND0.tif')\n",
        "b1 = os.path.join(imagem_dir, 'CBERS_4A_WPM_20210727_211_115_L4_BAND1.tif')\n",
        "b2 = os.path.join(imagem_dir, 'CBERS_4A_WPM_20210727_211_115_L4_BAND2.tif')\n",
        "b3 = os.path.join(imagem_dir, 'CBERS_4A_WPM_20210727_211_115_L4_BAND3.tif')\n",
        "b4 = os.path.join(imagem_dir, 'CBERS_4A_WPM_20210727_211_115_L4_BAND4.tif')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DDEAWwxtRs5P"
      },
      "source": [
        "# Composição Colorida"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "79KQY2-sRs5P"
      },
      "outputs": [],
      "source": [
        "# Diratório da composição\n",
        "\n",
        "composicao_output = os.path.join(workspace2, 'composicao.tif')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yja8i1ewRs5Q"
      },
      "outputs": [],
      "source": [
        "# Bandas para composição\n",
        "\n",
        "composicao = r'{};{};{};{}'.format(b4,b2,b3,b1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9cO0wYFlRs5Q"
      },
      "outputs": [],
      "source": [
        "# Composição das bandas\n",
        "\n",
        "arcpy.management.CompositeBands(in_rasters = composicao,\n",
        "                                out_raster = composicao_output)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u-xV_OG-Rs5R"
      },
      "source": [
        "# Pansharpene"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wTOx1X1pRs5R"
      },
      "outputs": [],
      "source": [
        "# Diretório do arquivo pansharpene\n",
        "\n",
        "pan_output = os.path.join(workspace2, 'pansharpene.tif')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "i81aCFcERs5R"
      },
      "outputs": [],
      "source": [
        "# Realizar o Pansharnepe\n",
        "\n",
        "arcpy.ia.Pansharpen(b0, composicao_output,True,'Gram-Schmidt').save(pan_output)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yqKLQ2ReRs5R"
      },
      "source": [
        "# Clip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nnGt_ud5Rs5S"
      },
      "outputs": [],
      "source": [
        "# Diretório do clip\n",
        "\n",
        "# Área de treino\n",
        "clip_training = os.path.join (workspace2, 'clip_training.tif')\n",
        "ROI_training = os.path.join (workspace1, 'ROI_training')\n",
        "\n",
        "# Área de teste\n",
        "clip_test = os.path.join (workspace2, 'clip_test.tif')\n",
        "ROI_test = os.path.join (workspace1, 'ROI_test')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MipNA6_IRs5S"
      },
      "outputs": [],
      "source": [
        "# Função para fazer o clip das área de interesse\n",
        "\n",
        "def clip_ROI (clip, ROI):\n",
        "  arcpy.Clip_management(pan_output, '',\n",
        "                      clip, ROI, '0', 'ClippingGeometry',\n",
        "                      'MAINTAIN_EXTENT')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Roodando a função clip\n",
        "\n",
        "clip_ROI (clip_training, ROI_training)\n",
        "clip_ROI (ROI_training, ROI_test)"
      ],
      "metadata": {
        "id": "Q_vt_6LsST4A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WHicIImPRs5S"
      },
      "source": [
        "# Classificando"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "59XmeeSgRs5S"
      },
      "outputs": [],
      "source": [
        "# Diretório das amostras e do esquema\n",
        "\n",
        "amostra_pixel = os.path.join(workspace2, 'amostras_GeoAI.shp')\n",
        "output_ecd = os.path.join(workspace2, \"Class_GeoAI.ecd\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hPVeqY8zRs5S"
      },
      "outputs": [],
      "source": [
        "# Treino e classificação por SVM\n",
        "\n",
        "arcpy.ia.TrainSupportVectorMachineClassifier(clip_training, amostra_pixel, output_ecd, '',\n",
        "                                            20, None, 'Classvalue')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wG8Kkpn2Rs5T"
      },
      "outputs": [],
      "source": [
        "# Diretório de classificação\n",
        "\n",
        "classificado = os.path.join(workspace2, 'classified.tif')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_L4lvEZnRs5T"
      },
      "outputs": [],
      "source": [
        "# Classificação das imagens\n",
        "\n",
        "out_raster_dataset = arcpy.ia.ClassifyRaster(clip_training, output_ecd, ''); out_raster_dataset.save(classificado)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lqXPhTVDRs5T"
      },
      "source": [
        "# Transformar raster to polygon"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pAPSDpxtRs5T"
      },
      "outputs": [],
      "source": [
        "# Diretório dos polígonos\n",
        "\n",
        "out_poligon = os.path.join(workspace1, 'poligons')\n",
        "classificada = os.path.join(workspace2, 'classified.tif')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FO4yTU2YRs5T"
      },
      "outputs": [],
      "source": [
        "# Raster to Polygon\n",
        "\n",
        "arcpy.conversion.RasterToPolygon(classificada,\n",
        "                                out_poligon,\n",
        "                                'SIMPLIFY',\n",
        "                                'Classvalue',\n",
        "                                'SINGLE_OUTER_PART',\n",
        "                                None)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qbX-jDM5Rs5U"
      },
      "source": [
        "# Imagem para Classificar"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nka43e79Rs5U"
      },
      "outputs": [],
      "source": [
        "# Diretório das imagem para classificar e amostras\n",
        "\n",
        "input_imagem = os.path.join(workspace2, 'clip_training.tif')\n",
        "out_amostras = os.path.join(workspace2, 'amostra')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gl3T-hABRs5U"
      },
      "outputs": [],
      "source": [
        "# Classificação da imagem\n",
        "\n",
        "arcpy.ia.ExportTrainingDataForDeepLearning(input_imagem,\n",
        "                                          out_amostras,\n",
        "                                          out_poligon,\n",
        "                                          'TIFF',\n",
        "                                          256,256,128,128,\n",
        "                                          'ONLY_TILES_WITH_FEATURES',\n",
        "                                          'Classified_Tiles',\n",
        "                                          0, 'gridcode',\n",
        "                                          0, None, 0,\n",
        "                                          'MAP_SPACE',\n",
        "                                          'PROCESS_AS_MOSAICKED_IMAGE',\n",
        "                                          'NO_BLACKEN',\n",
        "                                          'FIXED_SIZE',\n",
        "                                          None)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iVOFwjnMRs5U"
      },
      "source": [
        "# Treinando o Modelo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fPcrFAMLRs5V"
      },
      "outputs": [],
      "source": [
        "# Ler as amostras\n",
        "\n",
        "data = prepare_data(path = out_amostras,\n",
        "                   batch_size=3,\n",
        "                   dataset_type='Classified_Tiles',\n",
        "                   chip_size= 256)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bdNgER3FRs5V"
      },
      "outputs": [],
      "source": [
        "# Configurando o modelos\n",
        "\n",
        "model = UnetClassifier(data, backbone = 'resnet34')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jwMS2Cp1Rs5V"
      },
      "outputs": [],
      "source": [
        "# Learning Rate\n",
        "\n",
        "lr = 0.001"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7psVL2l4Rs5V"
      },
      "outputs": [],
      "source": [
        "# Treinamento do modelo em 40 épocas\n",
        "\n",
        "model.fit(40, lr=lr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l6O5uNBURs5V"
      },
      "outputs": [],
      "source": [
        "# Visualização das métricas de Precision, Recall, F1 e IOU\n",
        "\n",
        "metrics = model.per_class_metrics()\n",
        "metrics\n",
        "model.mIOU()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZknyQwdFRs5W"
      },
      "outputs": [],
      "source": [
        "# Resultado visual do treinamento\n",
        "\n",
        "model.show_results()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "7c5qTa99Rs5W"
      },
      "outputs": [],
      "source": [
        "# Salvar o modelo\n",
        "\n",
        "model.save('model_UNET')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rgVlgzexRs5W"
      },
      "source": [
        "# Classificando uma nova Imagem"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jxK5qvvQRs5W"
      },
      "outputs": [],
      "source": [
        "# Configuração de classificação\n",
        "\n",
        "# Diretórios para classificação\n",
        "nova_imagem = os.path.join (workspace2, 'clip_test.tif')\n",
        "modelo = os.path.join (workspace2, 'amostra\\models\\model_UNET\\model_UNET.dlpk')\n",
        "out_new_classified = os.path.join(workspace1, 'imagem_classify')\n",
        "\n",
        "# Definição dos parâmetros de classificação\n",
        "parametros = 'padding 56; batch_size 4; predict_background True; tile_size 256'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MhPOKVmURs5W"
      },
      "outputs": [],
      "source": [
        "# Classificação da nova imagem\n",
        "\n",
        "with arcpy.EnvManager (processorType='GPU'):\n",
        "    out_classified_raster = arcpy.ia.ClassifyPixelsUsingDeepLearning(nova_imagem,\n",
        "                                                                    modelo,\n",
        "                                                                    parametros,\n",
        "                                                                    'PROCESS_AS_MOSAICKED_IMAGE',\n",
        "                                                                    None); out_classified_raster.save(out_new_classified)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "file_extension": ".py",
      "name": "python",
      "version": "3"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}